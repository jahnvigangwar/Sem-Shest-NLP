{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Lab Assignment-IV**"
      ],
      "metadata": {
        "id": "bsycQ82uftQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">> Submitted by: **Jahnvi Gangwar (102003372), CO15**"
      ],
      "metadata": {
        "id": "VKchDVJGgAIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Convert the code of Fashion MNIST Classification implemented in Week 5, to PyTorch i.e., create, optimize, fit and evaluate neural network using PyTorch modules?"
      ],
      "metadata": {
        "id": "L4_9wsWrbvaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "ahg9M66Nb2la"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a Compose object that applies a series of transformations to the input images, namely converting them to tensors and normalizing their pixel values.\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n"
      ],
      "metadata": {
        "id": "PX5U4Zy6doa7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Fashion MNIST dataset and create separate datasets for the training and testing data.\n",
        "\n",
        "trainset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "id": "WTeemo8ucuPl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders for the training and testing data\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "ALYAUnBWd8jH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "abxclJqTbo0h"
      },
      "outputs": [],
      "source": [
        "# Define the neural network architecture\n",
        "\n",
        "# we define the architecture of the neural network using the nn.Sequential() function. \n",
        "# The first layer in the neural network is a nn.Flatten() layer which flattens the 28x28 input images into a 784-dimensional vector. \n",
        "# The next three layers are fully connected linear layers with ReLU activation functions. \n",
        "# The last layer outputs the final predictions, and has 10 output neurons (one for each class).\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(784, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 10)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "\n",
        "# we define the cross-entropy loss function, which is commonly used for multi-class classification tasks like these.\n",
        "# and also define the stochastic gradient descent (SGD) optimizer, which updates the parameters of the neural network using backpropagation \n",
        "# and a learning rate of 0.001, and a momentum value of 0.9.\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "zR3UsM-Zcxul"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the neural network\n",
        "\n",
        "# after we define the loss function (cross-entropy loss) and optimizer (stochastic gradient descent with momentum), \n",
        "# and train the neural network using a loop over the epochs and batches. \n",
        "# In each iteration, we pass a batch of input images and their corresponding labels through the neural network, \n",
        "# compute the loss, compute the gradients with respect to the parameters using backpropagation, \n",
        "# and update the parameters using the optimizer.\n",
        "\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 1000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYidJRn2c01C",
        "outputId": "6b9dd300-0c73-493a-e82d-4c2da850d8b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  1000] loss: 1.016\n",
            "[2,  1000] loss: 0.499\n",
            "[3,  1000] loss: 0.442\n",
            "[4,  1000] loss: 0.403\n",
            "[5,  1000] loss: 0.388\n",
            "[6,  1000] loss: 0.364\n",
            "[7,  1000] loss: 0.350\n",
            "[8,  1000] loss: 0.335\n",
            "[9,  1000] loss: 0.330\n",
            "[10,  1000] loss: 0.314\n",
            "Finished training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the neural network\n",
        "\n",
        "# Evaluate the trained neural network by computing the accuracy on the testing data. \n",
        "# Loop over the testing data, passing the input images through the neural network, and comparing the predicted class labels to the true labels. \n",
        "# Then compute the fraction of correct predictions as the accuracy.\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXnVXk_Dc3fA",
        "outputId": "792d3806-cbf5-489d-a71f-d23447c879a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 85 %\n"
          ]
        }
      ]
    }
  ]
}